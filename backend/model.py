# -*- coding: utf-8 -*-
"""mood+blend.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kWD1iB0lIPkQ8bFU78_Js3S69PKV_FXc
"""

import pandas as pd
import numpy as np
import ast
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import os
import ssl
import certifi
import pyaudio
import wave
import threading
import whisper
import re

os.environ['SSL_CERT_FILE'] = certifi.where()
ssl._create_default_https_context = ssl._create_unverified_context

# Load dataset
movies = pd.read_csv('./data/10000 Movies Data')

# Remove rows with null overviews
movies = movies[movies['overview'].notnull()].copy()
movies.reset_index(drop=True, inplace=True)  # <- important!

# Extract genres
def extract_genres(x):
    try:
        return [d['name'].lower().replace(" ", "") for d in ast.literal_eval(x)]
    except:
        return []

movies['Genres'] = movies['Genres'].apply(extract_genres)

# Combine fields for content-based filtering
def make_combined(row):
    genres = " ".join(row['Genres']) if isinstance(row['Genres'], list) else ""
    keywords = row['Keywords'] if isinstance(row['Keywords'], str) else ""
    overview = row['overview'] if isinstance(row['overview'], str) else ""
    return f"{overview} {genres} {keywords}"

movies['combined'] = movies.apply(make_combined, axis=1)

# TF-IDF on the cleaned and reindexed DataFrame
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(movies['combined'])

# Cosine similarity between aligned movie indices
content_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

mood_genre_mapping = {
    'happy': {'comedy': 0.4, 'family': 0.3, 'romance': 0.2, 'music': 0.1},
    'sad': {'drama': 0.5, 'romance': 0.3, 'documentary': 0.2},
    'thrilled': {'action': 0.5, 'thriller': 0.3, 'crime': 0.2},
    'scared': {'horror': 0.6, 'thriller': 0.3, 'mystery': 0.1},
    'curious': {'documentary': 0.5, 'history': 0.3, 'sciencefiction': 0.2},
    'nostalgic':{'history': 0.5, 'thriller': 0.3, 'drama': 0.2},
    'anxious':{'thriller': 0.4, 'mystery': 0.3, 'horror': 0.2, 'drama': 0.1},
    'bored':{'comedy': 0.4, 'animation': 0.3, 'adventure': 0.2, 'fantasy': 0.1}
}

# IMDb weighted rating formula
C = movies['vote_average'].mean()
m = movies['vote_count'].quantile(0.60)

def weighted_rating(x, m=m, C=C):
    v = x['vote_count']
    R = x['vote_average']
    return (v / (v + m)) * R + (m / (m + v)) * C

movies['weighted_rating'] = movies.apply(weighted_rating, axis=1)
# Normalize to 0â€“1
movies['weighted_rating_norm'] = (movies['weighted_rating'] - movies['weighted_rating'].min()) / \
                                  (movies['weighted_rating'].max() - movies['weighted_rating'].min())

import joblib

# Save the fitted vectorizer
joblib.dump(tfidf, './artifacts/tfidf_vectorizer.joblib')

joblib.dump(tfidf_matrix, './artifacts/tfidf_matrix.joblib')

# Save the processed DataFrame
joblib.dump(movies, './artifacts/movies_dataframe.joblib')

# Save the cosine similarity matrix if needed (optional)
joblib.dump(content_sim, './artifacts/content_sim.joblib')

# Save the mood_genre_mapping dictionary (optional, or redefine in backend)
joblib.dump(mood_genre_mapping, './artifacts/mood_genre_mapping.joblib')

def recommend_movies_by_mood(mood, user_history_titles=None, top_n=10, alpha=0.4, beta=0.3, gamma=0.3):
    genre_weights = mood_genre_mapping.get(mood, {})
    scores = []

    # Get user history indices
    user_sim = np.zeros(len(movies))
    user_history_titles_lower = [t.lower() for t in user_history_titles] if user_history_titles else []

    if user_history_titles:
        user_history_indices = movies[movies['title'].str.lower().isin(user_history_titles_lower)].index.tolist()
        if user_history_indices:
            user_profile_vector = np.mean(tfidf_matrix[user_history_indices], axis=0).A1
            user_sim = cosine_similarity([user_profile_vector], tfidf_matrix).flatten()

    for idx, row in movies.iterrows():
        # Skip movies already watched
        if row['title'].lower() in user_history_titles_lower:
            continue

        genres = row['Genres']

        # 1. Mood Score
        mood_score = sum([genre_weights.get(g, 0) for g in genres])

        # 2. Similarity Score
        sim_score = user_sim[idx]

        # 3. Normalized IMDb Weighted Rating
        rating_score = row['weighted_rating_norm']

        # Final Weighted Score
        final = alpha * mood_score + beta * sim_score + gamma * rating_score
        scores.append((row['title'], final, genres,row['poster_path'],row['release_date'],row['Movie_id']))

    scores.sort(key=lambda x: x[1], reverse=True)
    return pd.DataFrame(scores[:top_n], columns=['title', 'score', 'Genres','poster_path','release_date','Movie_id'])

recommend_movies_by_mood(
    mood='happy',
    user_history_titles=[
        "The Dark Knight",
        "Inception",
        "Iron Man",
        "The Matrix"
    ],
    top_n=10
)

import uuid

shared_blend_codes = {}

def create_blend_code(user_history, user_id="User1"):
    """
    Creates a new blend session and stores user history and ID.
    Returns the generated blend code.
    """
    code = str(uuid.uuid4())[:8]
    shared_blend_codes[code] = {
        "users": [user_id],
        "histories": {user_id: user_history}
    }
    return code

def join_blend_code(code, user_history, user_id="User2"):
    """
    Adds a user to an existing blend session.
    Returns recommendations and each user's tag.
    """
    if code not in shared_blend_codes:
        return {"error": "Invalid code."}

    blend_data = shared_blend_codes[code]

    # Only add user if not already in the blend
    if user_id not in blend_data["users"]:
        blend_data["users"].append(user_id)

    blend_data["histories"][user_id] = user_history

    # Build combined history for recommendations
    combined_histories = list(blend_data["histories"].values())
    recs = recommend_blend(combined_histories)

    # Calculate individual user tags
    user_tags = {
        uid: assign_tag_from_movie_history(history)
        for uid, history in blend_data["histories"].items()
    }

    return {
        "blend_code": code,
        "users": blend_data["users"],
        "user_tags": user_tags,
        "recommendations": recs
    }

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

def recommend_blend(user_histories, top_n=50, alpha=0.9, beta=0.1):
    """
    Recommends movies for a group blend session using a combination of cosine similarity
    (from TF-IDF vectors of watched movies) and normalized rating scores.

    Parameters:
        user_histories (List[List[str]]): List of lists, each with movie titles watched by a user.
        top_n (int): Number of top recommendations to return.
        alpha (float): Weight for similarity score.
        beta (float): Weight for rating score.

    Returns:
        dict: {
            "blend_recommendations": List of recommended movies,
            "overall_match_score": Percentage match score across top_n movies
        }
    """
    if not user_histories or not all(user_histories):
        return []

    # Normalize user history (lowercase & deduplicate)
    cleaned_histories = [set(title.lower().strip() for title in history if title.strip()) for history in user_histories]
    all_titles = set.union(*cleaned_histories)

    if not all_titles:
        return []

    # Get indices of the watched movies
    indices = movies[movies['title'].str.lower().isin(all_titles)].index.tolist()
    if not indices:
        return []

    # Build blend profile vector from TF-IDF matrix
    profile_vector = np.mean(tfidf_matrix[indices], axis=0).A1
    user_sim = cosine_similarity([profile_vector], tfidf_matrix).flatten()

    # Normalize rating (if not already)
    if 'weighted_rating_norm' not in movies.columns:
        min_rating = movies['weighted_rating'].min()
        max_rating = movies['weighted_rating'].max()
        if max_rating != min_rating:
            movies['weighted_rating_norm'] = (movies['weighted_rating'] - min_rating) / (max_rating - min_rating)
        else:
            movies['weighted_rating_norm'] = 0.5  # fallback default

    scores = []

    for idx, row in movies.iterrows():
        title_lc = row['title'].lower()
        if title_lc in all_titles:
            continue

        sim_score = user_sim[idx]
        rating_score = row.get('weighted_rating_norm', 0.5)  # fallback if missing
        match_score = alpha * sim_score + beta * rating_score

        scores.append({
            "title": row['title'],
            "genres": row['Genres'],
            "match_score": round(match_score, 4),
            "poster_path": row.get('poster_path', ''),
            "release_date": row.get('release_date', '')
        })

    # Sort and return top recommendations
    scores.sort(key=lambda x: x['match_score'], reverse=True)

    overall_match_raw = np.mean([x['match_score'] for x in scores[:top_n]]) if scores else 0.0
    overall_match_percent = round(overall_match_raw * 100, 2)

    return {
        "blend_recommendations": scores[:top_n],
        "overall_match_score": f"{overall_match_percent}%"
    }

from collections import Counter

# --- Part 1: Genre Tagging Logic ---

GENRE_TAGS = {
    'Action': "Adrenaline Addict",
    'Adventure': "Pookie Princess",
    'Animation': "Whimsy Wizard",
    'Comedy': "Laugh Track Legend",
    'Crime': "Plot Twist Prophet",
    'Documentary': "Truth Teller",
    'Drama': "Feeling Architect",
    'Family': "Heartfelt Hero",
    'Fantasy': "Pookie Princess",
    'History': "Time Travel Thinker",
    'Horror': "Scream Scholar",
    'Music': "Harmony Hunter",
    'Mystery': "Plot Twist Prophet",
    'Romance': "Love Plot Loyalist",
    'Science Fiction': "Galactic Overthinker",
    'TV Movie': "Screen Critic",
    'Thriller': "Plot Twist Prophet",
    'War': "Battle Bard",
    'Western': "Cowboy Chronicler",
    'Sci-Fi': "Galactic Overthinker"  # alias
}

def get_genre_tag(user_watched_genres):
    """
    Assigns a tag to a user based on their most-watched genres.
    """
    if not user_watched_genres:
        return "No Tag"

    genre_counts = Counter(user_watched_genres)
    most_common_genre = genre_counts.most_common(1)[0][0]

    if most_common_genre == 'Sci-Fi':
        most_common_genre = 'Science Fiction'

    return GENRE_TAGS.get(most_common_genre, "No Tag")

# --- Part 2: Load Movie Data and Create Title-to-Genre Mapping ---

try:
    movies_df = pd.read_csv('./data/10000 Movies Data')
except FileNotFoundError:
    print("Error: '10000 Movies Data' not found. Please ensure the file is in the correct directory.")
    exit()

def extract_genres_from_string(genres_str):
    if isinstance(genres_str, str):
        try:
            return [d['name'] for d in ast.literal_eval(genres_str)]
        except (ValueError, SyntaxError):
            return []
    return []

movies_df['parsed_genres'] = movies_df['Genres'].apply(extract_genres_from_string)

movie_title_to_genres = {}
for index, row in movies_df.iterrows():
    title = row['title']
    genres = row['parsed_genres']
    if title not in movie_title_to_genres:
        movie_title_to_genres[title] = genres

# --- Part 3: Function to Process User History (Movie Titles) and Assign Tags ---

def assign_tag_from_movie_history(user_movie_history):
    """
    Assigns a genre tag based on a (possibly nested) list of movie titles.
    Accepts flat or nested lists of movie titles.
    """
    all_genres_from_history = []

    # Flatten the input if it's a nested list
    flat_movie_list = []
    for item in user_movie_history:
        if isinstance(item, list):
            flat_movie_list.extend(item)
        else:
            flat_movie_list.append(item)

    # Collect genres for each movie title
    for movie_title in flat_movie_list:
        genres = movie_title_to_genres.get(movie_title)
        if genres:
            all_genres_from_history.extend(genres)

    return get_genre_tag(all_genres_from_history)

# Alice starts a blend
code = create_blend_code(['Inception', 'Interstellar'], user_id="Alice")

# Bob joins
join_blend_code(code, ['Frozen', 'Moana'], user_id="Bob")

join_blend_code(code, ['Se7en', 'The Godfather'], user_id="Charlie")

def recommend_for_user(user_history, top_n=25, alpha=0.9, beta=0.1):
    """
    Recommends movies for an individual user based on their watch history using
    a combination of cosine similarity and normalized rating scores.

    Parameters:
        user_history (List[str]): List of movie titles watched by the user.
        top_n (int): Number of top recommendations to return.
        alpha (float): Weight for similarity score.
        beta (float): Weight for rating score.

    Returns:
        dict: {
            "user_recommendations": List of recommended movies,
            "overall_match_score": Percentage match score across top_n movies
        }
    """
    if not user_history:
        return []

    # Normalize user history (lowercase & deduplicate)
    cleaned_history = set(title.lower().strip() for title in user_history if title.strip())
    if not cleaned_history:
        return []

    # Get indices of the watched movies
    indices = movies[movies['title'].str.lower().isin(cleaned_history)].index.tolist()
    if not indices:
        return []

    # Build user profile vector from TF-IDF matrix
    profile_vector = np.mean(tfidf_matrix[indices], axis=0).A1
    user_sim = cosine_similarity([profile_vector], tfidf_matrix).flatten()

    # Normalize rating (if not already)
    if 'weighted_rating_norm' not in movies.columns:
        min_rating = movies['weighted_rating'].min()
        max_rating = movies['weighted_rating'].max()
        if max_rating != min_rating:
            movies['weighted_rating_norm'] = (movies['weighted_rating'] - min_rating) / (max_rating - min_rating)
        else:
            movies['weighted_rating_norm'] = 0.5  # fallback default

    scores = []

    for idx, row in movies.iterrows():
        title_lc = row['title'].lower()
        if title_lc in cleaned_history:
            continue

        sim_score = user_sim[idx]
        rating_score = row.get('weighted_rating_norm', 0.5)
        match_score = alpha * sim_score + beta * rating_score

        scores.append({
            "title": row['title'],
            "genres": row['Genres'],
            "match_score": round(match_score, 4),
            "poster_path": row.get('poster_path', ''),
            "release_date": row.get('release_date', '')
        })

    # Sort and return top recommendations
    scores.sort(key=lambda x: x['match_score'], reverse=True)

    overall_match_raw = np.mean([x['match_score'] for x in scores[:top_n]]) if scores else 0.0
    overall_match_percent = round(overall_match_raw * 100, 2)

    return {
        "user_recommendations": scores[:top_n],
        "overall_match_score": f"{overall_match_percent}%"
    }

user_history = [
    "Inception",
    "The Dark Knight",
    "Interstellar"
]

def record_until_enter(output_filename="output.wav", sample_rate=44100, channels=1):
    chunk_size = 1024
    audio_format = pyaudio.paInt16
    frames = []
    recording = True

    def record_thread():
        nonlocal recording
        p = pyaudio.PyAudio()
        stream = p.open(format=audio_format,
                        channels=channels,
                        rate=sample_rate,
                        input=True,
                        frames_per_buffer=chunk_size)
        print("Recording... Press Enter to stop.")
        while recording:
            data = stream.read(chunk_size)
            frames.append(data)
        stream.stop_stream()
        stream.close()
        p.terminate()

    t = threading.Thread(target=record_thread)
    t.start()
    input()  # Wait for Enter key
    recording = False
    t.join()

    wf = wave.open(output_filename, 'wb')
    wf.setnchannels(channels)
    wf.setsampwidth(pyaudio.PyAudio().get_sample_size(audio_format))
    wf.setframerate(sample_rate)
    wf.writeframes(b''.join(frames))
    wf.close()
    print("Recording stopped and saved to", output_filename)

def transcribe_voice(audio_path):
    model = whisper.load_model("medium")
    result = model.transcribe(audio_path)
    return result['text']

def extract_query_keywords(query):
    stopwords = set([
        'the', 'a', 'an', 'and', 'or', 'to', 'in', 'of', 'with', 'for', 'on', 'at', 'by', 'so', 'i', 'was', 'it', 'like',
        'that', 'this', 'but', 'as', 'is', 'be', 'are', 'were', 'do', 'does', 'did', 'if', 'then', 'than', 'from', 'about',
        'my', 'me', 'you', 'something', 'movie', 'film', 'watch', 'see', 'would', 'really', 'maybe', 'thinking'
    ])
    words = re.findall(r'\w+', query.lower())
    keywords = [w for w in words if w not in stopwords]
    return set(keywords)

def extract_reference_movie(user_query, movie_titles):
    for title in movie_titles:
        pattern = r'\b' + re.escape(title.lower()) + r'\b'
        if re.search(pattern, user_query.lower()):
            return title
    return None

def clean_query(user_query, ref_movie):
    if ref_movie:
        return user_query.replace(ref_movie, '').strip()
    return user_query

def keyword_genre_boost(row, query_keywords):
    boost = 0
    if isinstance(row['Keywords'], str):
        movie_keywords = set(kw.strip().lower() for kw in row['Keywords'].split(','))
        if movie_keywords & query_keywords:
            boost += 0.3
    if isinstance(row['Genres'], list):
        movie_genres = set(g.lower() for g in row['Genres'])
        if movie_genres & query_keywords:
            boost += 0.2
    return boost

def enhanced_descriptive_recommendation(
    user_query,
    movies,
    tfidf,
    tfidf_matrix,
    user_history_titles=None,
    top_n=10,
    alpha=0.5,
    beta=0.3,
    gamma=0.2
):
    query_keywords = extract_query_keywords(user_query)
    movie_titles = movies['title'].tolist()
    ref_movie = extract_reference_movie(user_query, movie_titles)
    desc_query = clean_query(user_query, ref_movie)

    user_history_titles = user_history_titles or []
    if ref_movie and ref_movie not in user_history_titles:
        user_history_titles = user_history_titles + [ref_movie]
    user_history_titles_lower = [t.lower() for t in user_history_titles]

    if user_history_titles:
        user_history_indices = movies[movies['title'].str.lower().isin(user_history_titles_lower)].index.tolist()
        if user_history_indices:
            user_profile_vector = np.mean(tfidf_matrix[user_history_indices], axis=0).A1
            user_sim = cosine_similarity([user_profile_vector], tfidf_matrix).flatten()
        else:
            user_sim = np.zeros(len(movies))
    else:
        user_sim = np.zeros(len(movies))

    desc_vec = tfidf.transform([desc_query])
    desc_sim = cosine_similarity(desc_vec, tfidf_matrix).flatten()

    if 'weighted_rating_norm' not in movies.columns:
        min_rating = movies['weighted_rating'].min()
        max_rating = movies['weighted_rating'].max()
        if max_rating != min_rating:
            movies['weighted_rating_norm'] = (movies['weighted_rating'] - min_rating) / (max_rating - min_rating)
        else:
            movies['weighted_rating_norm'] = 0.5

    scores = []
    for idx, row in movies.iterrows():
        title_lc = row['title'].lower()
        if title_lc in user_history_titles_lower:
            continue
        sim_score = desc_sim[idx]
        profile_score = user_sim[idx]
        rating_score = row['weighted_rating_norm']
        boost = keyword_genre_boost(row, query_keywords)
        final_score = alpha * sim_score + beta * profile_score + gamma * rating_score + boost
        scores.append((row['Movie_id'], row['title'], row['Genres'], row['release_date'], row['Keywords'],
                       row['overview'], row['poster_path'], row['Budget'], row['Revenue'],
                       row['popularity'], row['vote_average'], row['vote_count'], final_score))
    scores.sort(key=lambda x: x[-1], reverse=True)
    columns = ['Movie_id', 'title', 'Genres', 'release_date', 'Keywords', 'overview', 'poster_path',
               'Budget', 'Revenue', 'popularity', 'vote_average', 'vote_count', 'score']
    return pd.DataFrame(scores[:top_n], columns=columns)

def handle_voice_search(audio_path, user_history_titles=None, top_n=5):
    user_query = transcribe_voice(audio_path)
    print("\nTranscribed text:", user_query)
    recommendations = enhanced_descriptive_recommendation(
        user_query, movies, tfidf, tfidf_matrix,
        user_history_titles=user_history_titles, top_n=top_n
    )
    return recommendations